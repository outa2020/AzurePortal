{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a training script with the Python SDK\n",
        "\n",
        "You can use the Python SDK for Azure Machine Learning to submit scripts as jobs. By using jobs, you can easily keep track of the input parameters and outputs when training a machine learning model.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1762278584175
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.27.1\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: /anaconda/envs/azureml_py38/lib/python3.10/site-packages\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, pydash, pyjwt, pyyaml, six, strictyaml, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1762278588220
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1762278593447
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n",
            "Overriding of current TracerProvider is not allowed\n",
            "Overriding of current LoggerProvider is not allowed\n",
            "Overriding of current MeterProvider is not allowed\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n",
            "Attempting to instrument while already instrumented\n"
          ]
        }
      ],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select Show for the Key field under key1.\n",
        "Copy the value of the Key field to a notepad. You'll need to paste this value into the notebook later.\n",
        "Copy the name of your storage account from the top of the page. The name should start with mlwdp100storage...\n",
        "#access key, key1\n",
        "MzYtM18zEmkiHiHgpwq1XccIB0F0WkZ+bYniIGWOLDgmycK7M0VK3VrdugGf+3GrECs254BiEQ3n+ASt1lt1XQ==\n",
        "# name of storage account:\n",
        "mlwhhndestorage7d141eba5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/cidev20251103/code/Users/Mohamed.Outahajala/azure-ml-labs/Labs/02\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory set to: /mnt/batch/tasks/shared/LS_root/mounts/clusters/cidev20251103/code/Users/Mohamed.Outahajala/azure-ml-labs/Labs/02\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/home/azureuser/cloudfiles/code/Users/Mohamed.Outahajala/azure-ml-labs/Labs/02')\n",
        "print(\"Working directory set to:\", os.getcwd())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use the Python SDK to train a model\n",
        "\n",
        "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** file in the same folder as the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
            "0    1354778            0            171                      80   \n",
            "1    1147438            8             92                      93   \n",
            "2    1640031            7            115                      47   \n",
            "3    1883350            9            103                      78   \n",
            "4    1424119            1             85                      59   \n",
            "\n",
            "   TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n",
            "0                34            23  43.509726          1.213191   21         0  \n",
            "1                47            36  21.240576          0.158365   23         0  \n",
            "2                52            35  41.511523          0.079019   23         0  \n",
            "3                25           304  29.582192          1.282870   43         1  \n",
            "4                27            35  42.604536          0.549542   22         0  \n"
          ]
        }
      ],
      "source": [
        "# make sure diabetes.csv is src folder\n",
        "import pandas as pd\n",
        "diabetes = pd.read_csv('./src/diabetes.csv')\n",
        "print(diabetes.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/diabetes-training.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/diabetes-training.py\n",
        "# import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import joblib\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv('./diabetes.csv')\n",
        "\n",
        "# separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# set regularization hyperparameter\n",
        "reg = 0.01\n",
        "\n",
        "# train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# save the model\n",
        "output_path = './outputs/model.pkl'\n",
        "os.makedirs('./outputs', exist_ok=True)  # Ensure the outputs directory exists\n",
        "joblib.dump(model, output_path)\n",
        "print(f\"Model saved to {output_path}\")\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test, y_scores[:,1])\n",
        "print('AUC: ' + str(auc))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the cell below to submit the job that trains a classification model to predict diabetes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1762278812324
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/green_line_blq9fsr82c?wsid=/subscriptions/0ded687b-997b-4159-acf3-9c82e7352f8c/resourcegroups/rg-hhn-dev/workspaces/mlw-hhn-dev-20251103&tid=e08b7eef-b501-4a67-9ed0-07e38bfccee7\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python diabetes-training.py\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster-dev\",\n",
        "    display_name=\"diabetes-pythonv2-train_regression-job\",\n",
        "    experiment_name=\"diabetes-training-regression-experiment\",\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "green_line_blq9fsr82c job submitted successfully.\n"
          ]
        }
      ],
      "source": [
        "print(returned_job.name + \" job submitted successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/cidev20251103/code/Users/Mohamed.Outahajala/azure-ml-labs/Labs/02\n"
          ]
        }
      ],
      "source": [
        "#check current directory\n",
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model registered: diabetes-logistic-regression (version: 1)\n"
          ]
        }
      ],
      "source": [
        "# Step 1\n",
        "# # Register the model from the job outputs\n",
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# Get the job name\n",
        "job_name = returned_job.name\n",
        "\n",
        "model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/outputs/model.pkl\",\n",
        "    name=\"diabetes-logistic-regression\",\n",
        "    description=\"Logistic regression model for diabetes prediction\",\n",
        "    type=AssetTypes.CUSTOM_MODEL,\n",
        "    tags={\"accuracy\": \"0.774\", \"AUC\": \"0.848\"}\n",
        ")\n",
        "\n",
        "registered_model = ml_client.models.create_or_update(model)\n",
        "print(f\"✅ Model registered: {registered_model.name} (version: {registered_model.version})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2 : Create a scoring script\n",
        "Create a scoring script that will handle inference requests:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/score.py\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def init():\n",
        "    \"\"\"\n",
        "    This function is called when the container is initialized/started.\n",
        "    \"\"\"\n",
        "    global model\n",
        "    # Get the path to the registered model file and load it\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "def run(raw_data):\n",
        "    \"\"\"\n",
        "    This function is called for every invocation of the endpoint.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(raw_data)['data']\n",
        "        data = np.array(data)\n",
        "        result = model.predict(data)\n",
        "        # Return predictions as JSON\n",
        "        return json.dumps({\"result\": result.tolist()})\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return json.dumps({\"error\": error})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Create Environment Configuration\n",
        "Create a conda dependencies file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing src/conda.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/conda.yml\n",
        "name: model-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - numpy\n",
        "  - pip\n",
        "  - scikit-learn\n",
        "  - scipy\n",
        "  - pip:\n",
        "      - azureml-defaults\n",
        "      - inference-schema[numpy-support]\n",
        "      - joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Create a Managed Online Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a unique endpoint name\n",
        "endpoint_name = f\"diabetes-endpoint-{datetime.now().strftime('%m%d%H%M%f')}\"\n",
        "\n",
        "# Define the endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"Endpoint for diabetes prediction\",\n",
        "    auth_mode=\"key\"  # or \"aml_token\" for Azure AD authentication\n",
        ")\n",
        "\n",
        "# Create the endpoint\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(f\"✅ Endpoint created: {endpoint_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 5: Create a Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n",
        "\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",  # Deployment name\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=registered_model.id,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\",\n",
        "        scoring_script=\"score.py\"\n",
        "    ),\n",
        "    environment=f\"azureml://registries/azureml/environments/sklearn-1.0/versions/latest\",\n",
        "    instance_type=\"Standard_DS2_v2\",\n",
        "    instance_count=1\n",
        ")\n",
        "\n",
        "# Create the deployment\n",
        "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
        "print(f\"✅ Deployment created: blue\")\n",
        "\n",
        "# Set traffic to 100% for this deployment\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(\"✅ Traffic set to 100% for blue deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 6: Test the Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Sample test data (8 features)\n",
        "test_data = {\n",
        "    \"data\": [\n",
        "        [2, 180, 74, 24, 21, 23.9, 1.488, 22],  # Sample patient data\n",
        "        [0, 148, 58, 11, 179, 39.19, 0.160, 45]\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Invoke the endpoint\n",
        "response = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=endpoint_name,\n",
        "    request_file=None,\n",
        "    deployment_name=\"blue\",\n",
        "    request_body=json.dumps(test_data)\n",
        ")\n",
        "\n",
        "print(\"Prediction result:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7: Get Endpoint Details and Use it Externally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#step 7\n",
        "# Get the endpoint details\n",
        "endpoint_details = ml_client.online_endpoints.get(name=endpoint_name)\n",
        "\n",
        "# Get the scoring URI\n",
        "scoring_uri = endpoint_details.scoring_uri\n",
        "print(f\"Scoring URI: {scoring_uri}\")\n",
        "\n",
        "# Get the authentication key\n",
        "keys = ml_client.online_endpoints.get_keys(name=endpoint_name)\n",
        "primary_key = keys.primary_key\n",
        "print(f\"Primary Key: {primary_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 8: Use the Endpoint with REST API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#step 8\n",
        "import requests\n",
        "\n",
        "# Prepare the request\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Bearer {primary_key}'\n",
        "}\n",
        "\n",
        "test_data = {\n",
        "    \"data\": [\n",
        "        [2, 180, 74, 24, 21, 23.9, 1.488, 22]\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Make the prediction request\n",
        "response = requests.post(scoring_uri, json=test_data, headers=headers)\n",
        "print(f\"Status Code: {response.status_code}\")\n",
        "print(f\"Response: {response.json()}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
