{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a training script with the Python SDK\n",
        "\n",
        "You can use the Python SDK for Azure Machine Learning to submit scripts as jobs. By using jobs, you can easily keep track of the input parameters and outputs when training a machine learning model.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install azure-ai-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1762278584175
        }
      },
      "outputs": [],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1762278588220
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1762278593447
        }
      },
      "outputs": [],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select Show for the Key field under key1.\n",
        "Copy the value of the Key field to a notepad. You'll need to paste this value into the notebook later.\n",
        "Copy the name of your storage account from the top of the page. The name should start with mlwdp100storage...\n",
        "#access key, key1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/home/azureuser/cloudfiles/code/Users/Mohamed.Outahajala/AzurePortal')\n",
        "print(\"Working directory set to:\", os.getcwd())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use the Python SDK to train a model\n",
        "\n",
        "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** file in the same folder as the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make sure diabetes.csv is src folder\n",
        "import pandas as pd\n",
        "diabetes = pd.read_csv('./src/diabetes.csv')\n",
        "print(diabetes.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile src/diabetes-training.py\n",
        "# import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import joblib\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv('./diabetes.csv')\n",
        "\n",
        "# separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# set regularization hyperparameter\n",
        "reg = 0.01\n",
        "\n",
        "# train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg)\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# save the model\n",
        "output_path = './outputs/model.pkl'\n",
        "os.makedirs('./outputs', exist_ok=True)  # Ensure the outputs directory exists\n",
        "joblib.dump(model, output_path)\n",
        "print(f\"Model saved to {output_path}\")\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test, y_scores[:,1])\n",
        "print('AUC: ' + str(auc))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the cell below to submit the job that trains a classification model to predict diabetes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1762278812324
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python diabetes-training.py\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster-dev\",\n",
        "    display_name=\"diabetes-pythonv2-train_regression-job\",\n",
        "    experiment_name=\"diabetes-training-regression-experiment\",\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(returned_job.name + \" job submitted successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#check current directory\n",
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1\n",
        "# # Register the model from the job outputs\n",
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# Get the job name\n",
        "job_name = returned_job.name\n",
        "\n",
        "model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/outputs/model.pkl\",\n",
        "    name=\"diabetes-logistic-regression\",\n",
        "    description=\"Logistic regression model for diabetes prediction\",\n",
        "    type=AssetTypes.CUSTOM_MODEL,\n",
        "    tags={\"accuracy\": \"0.774\", \"AUC\": \"0.848\"}\n",
        ")\n",
        "\n",
        "registered_model = ml_client.models.create_or_update(model)\n",
        "print(f\"✅ Model registered: {registered_model.name} (version: {registered_model.version})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the registered model by name\n",
        "model_name = \"diabetes-logistic-regression\"\n",
        "registered_model = ml_client.models.get(name=model_name, version=1)\n",
        "\n",
        "# Print the model ID\n",
        "print(f\"Registered Model ID: {registered_model.id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2 : Create a scoring script\n",
        "Create a scoring script that will handle inference requests:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile src/score.py\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def init():\n",
        "    \"\"\"\n",
        "    This function is called when the container is initialized/started.\n",
        "    \"\"\"\n",
        "    global model\n",
        "    # Get the path to the registered model file and load it\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "    print(\"Model loaded successfully\")\n",
        "\n",
        "def run(raw_data):\n",
        "    \"\"\"\n",
        "    This function is called for every invocation of the endpoint.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = json.loads(raw_data)['data']\n",
        "        data = np.array(data)\n",
        "        result = model.predict(data)\n",
        "        # Return predictions as JSON\n",
        "        return json.dumps({\"result\": result.tolist()})\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return json.dumps({\"error\": error})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Create Environment Configuration\n",
        "Create a conda dependencies file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile src/conda.yml\n",
        "name: model-env\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - numpy\n",
        "  - pip\n",
        "  - scikit-learn\n",
        "  - scipy\n",
        "  - pip:\n",
        "      - azureml-defaults\n",
        "      - inference-schema[numpy-support]\n",
        "      - joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Create a Managed Online Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a unique endpoint name\n",
        "endpoint_name = f\"diabetes-endpoint-{datetime.now().strftime('%m%d%H%M%f')}\"\n",
        "\n",
        "# Define the endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"Endpoint for diabetes prediction\",\n",
        "    auth_mode=\"key\"  # or \"aml_token\" for Azure AD authentication\n",
        ")\n",
        "\n",
        "# Create the endpoint\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(f\"✅ Endpoint created: {endpoint_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "environments = ml_client.environments.list()\n",
        "for env in environments:\n",
        "    print(f\"Name: {env.name}, Version: {env.version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "environment = \"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Step 5 Create a Deployment\n",
        "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n",
        "\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",  # Deployment name \n",
        "    endpoint_name=endpoint_name, # Endpoint name diabetes-endpoint-11051251184959\n",
        "    model=registered_model.id,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\",\n",
        "        scoring_script=\"score.py\"\n",
        "    ),\n",
        "    environment=environment,\n",
        "    instance_type=\"Standard_DS2_v2\",\n",
        "    instance_count=1\n",
        ")\n",
        "\n",
        "# Create the deployment\n",
        "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
        "print(f\"✅ Deployment created: blue\")\n",
        "\n",
        "# Set traffic to 100% for this deployment\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "print(\"✅ Traffic set to 100% for blue deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 6: Test the Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Endpoint URL: {ml_client.online_endpoints.get(name=endpoint_name).scoring_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print endpoint name\n",
        "print(f\"Endpoint Name: {endpoint_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import urllib.request\n",
        "# Define the correct endpoint name\n",
        "\n",
        "# Retrieve the primary key\n",
        "keys = ml_client.online_endpoints.get_keys(name=endpoint_name)\n",
        "primary_key = keys.primary_key\n",
        "\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "\n",
        "data = {\n",
        "    \"data\": [\n",
        "        [5, 200, 80, 30, 100, 35.0, 0.500, 50],  # \\returns 1 (diabetic)\n",
        "        [1, 100, 60, 20, 50, 22.0, 0.200, 25]   # returns 0 (non-diabetic)\n",
        "    ]\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "# Get the endpoint details\n",
        "endpoint_details = ml_client.online_endpoints.get(name=endpoint_name)\n",
        "url = endpoint_details.scoring_uri\n",
        "# Replace this with the primary/secondary key, AMLToken, or Microsoft Entra ID token for the endpoint\n",
        "api_key = primary_key\n",
        "if not api_key:\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
        "\n",
        "\n",
        "headers = {'Content-Type':'application/json', 'Accept': 'application/json', 'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 7: Get Endpoint Details and Use it Externally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#step 7\n",
        "# Get the endpoint details\n",
        "endpoint_details = ml_client.online_endpoints.get(name=endpoint_name)\n",
        "\n",
        "# Get the scoring URI\n",
        "scoring_uri = endpoint_details.scoring_uri\n",
        "print(f\"Scoring URI: {scoring_uri}\")\n",
        "\n",
        "# Get the authentication key - Store securely, do not print in notebook\n",
        "keys = ml_client.online_endpoints.get_keys(name=endpoint_name)\n",
        "primary_key = keys.primary_key\n",
        "# NOTE: Never print or commit the primary_key. Use environment variables instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#step 8\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# Get credentials from environment variables (set these securely in Azure Key Vault)\n",
        "primary_key = os.getenv('ENDPOINT_KEY')\n",
        "scoring_uri = os.getenv('SCORING_URI')\n",
        "\n",
        "if not primary_key or not scoring_uri:\n",
        "    print(\"ERROR: Set ENDPOINT_KEY and SCORING_URI environment variables\")\n",
        "else:\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'Authorization': f'Bearer {primary_key}'\n",
        "    }\n",
        "\n",
        "    test_data = {\n",
        "        \"data\": [\n",
        "            [2, 180, 74, 24, 21, 23.9, 1.488, 22]\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Make the prediction request\n",
        "    response = requests.post(scoring_uri, json=test_data, headers=headers)\n",
        "    print(f\"Status Code: {response.status_code}\")\n",
        "    print(f\"Response: {response.json()}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
