{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5354c6bd",
   "metadata": {},
   "source": [
    "Linen usage prediction for the next 30 days / 7 days\n",
    "> Using Azure ML SDK v2 (MLClient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install SDK v2 (run once in the notebook if needed)\n",
    "!pip install --quiet azure-ai-ml azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip show azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect using MLClient (SDK v2)\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# MLClient will read configuration from ./config.json or env vars if present\n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "print('MLClient initialized for subscription/workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./src/usage.csv')\n",
    "print(df.columns.tolist())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6244162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_column_name = 'LinenUsage'\n",
    "time_column_name = 'Date'\n",
    "forecast_horizon = 30\n",
    "df[time_column_name] = pd.to_datetime(df[time_column_name])\n",
    "df = df.sort_values(time_column_name).reset_index(drop=True)\n",
    "print(df.dtypes)\n",
    "print('Rows:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get a compute target via MLClient (AmlCompute entity)\n",
    "compute_name = 'cpu-cluster' # to be repalced by the cluster name in Azure\n",
    "existing = {c.name: c for c in ml_client.compute.list()}\n",
    "if compute_name in existing:\n",
    "    print('Found compute:', compute_name)\n",
    "else:\n",
    "    print('Creating compute:', compute_name)\n",
    "    compute = AmlCompute(name=compute_name, size='STANDARD_D2_V2', min_instances=0, max_instances=4)\n",
    "    ml_client.compute.begin_create_or_update(compute).result()\n",
    "    print('Compute created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03918bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MLflow (run once if needed)\n",
    "!pip install --quiet mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MLflow local tracking (change URI to server if you have one)\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('file:./mlruns')\n",
    "mlflow.set_experiment('linen-forecast-experiment')\n",
    "print('MLflow tracking URI:', mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca34bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AutoML forecasting job and submit it while logging to MLflow\n",
    "from azure.ai.ml.automl import forecasting\n",
    "import json, os\n",
    "\n",
    "# Use Input to point to the local CSV - MLClient will handle upload as needed\n",
    "training_data = Input(type='uri_file', path='./src/usage.csv')\n",
    "\n",
    "# Create a forecasting job: disable ensembling and block non-interpretable algos\n",
    "job = forecasting(\n",
    "    training_data=training_data,\n",
    "    target_column_name=target_column_name,\n",
    "    time_column_name=time_column_name,\n",
    "    primary_metric='normalized_root_mean_squared_error',\n",
    "    compute=compute_name,\n",
    "    experiment_name='linen-forecast-automl-v2',\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    featurization='auto',\n",
    "    enable_ensembling=False,\n",
    "    enable_stack_ensemble=False,\n",
    "    blocked_training_algorithms=['LightGBM', 'DeepAR', 'ExtremeRandomTrees'],\n",
    "    limits={\n",
    "        'max_concurrent_trials': 4,\n",
    "        'timeout_minutes': 60\n",
    "    }\n",
    ")\n",
    "\n",
    "# Submit the job within an MLflow run so we capture params/metadata/artifacts\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param('forecast_horizon', forecast_horizon)\n",
    "    mlflow.log_param('target_column', target_column_name)\n",
    "    mlflow.log_param('time_column', time_column_name)\n",
    "    mlflow.log_param('compute', compute_name)\n",
    "    mlflow.log_param('blocked_algos', ','.join(job.blocked_training_algorithms or []))\n",
    "\n",
    "    returned_job = ml_client.jobs.create_or_update(job)\n",
    "    mlflow.log_param('azureml_job_name', returned_job.name)\n",
    "    print('Submitted job:', returned_job.name)\n",
    "\n",
    "    # Stream job status to notebook\n",
    "    ml_client.jobs.stream(returned_job.name)\n",
    "\n",
    "    # After completion gather details and artifacts\n",
    "    job_details = ml_client.jobs.get(returned_job.name)\n",
    "    mlflow.log_param('job_status', job_details.status)\n",
    "\n",
    "    # Save job JSON for traceability and log as artifact\n",
    "    job_json_path = 'job_details_{}.json'.format(returned_job.name)\n",
    "    with open(job_json_path, 'w') as f:\n",
    "        json.dump(job_details._to_rest_object().serialize(), f)  # serialize REST payload\n",
    "    mlflow.log_artifact(job_json_path)\n",
    "\n",
    "    # Download job artifacts (if any) and log them\n",
    "    artifacts_dir = './job_artifacts_{}'.format(returned_job.name)\n",
    "    os.makedirs(artifacts_dir, exist_ok=True)\n",
    "    try:\n",
    "        ml_client.jobs.download(returned_job.name, download_path=artifacts_dir)\n",
    "        mlflow.log_artifacts(artifacts_dir)\n",
    "    except Exception as ex:\n",
    "        print('No artifacts to download or download failed:', ex)\n",
    "\n",
    "    # If you'd like, inspect job_details to find the best child trial and log its metrics\n",
    "    # This is a generic example: inspect job_details.properties or job_details.child_jobs for trial info\n",
    "    try:\n",
    "        # attempt to log top-level metrics if present\n",
    "        if hasattr(job_details, 'properties') and job_details.properties:\n",
    "            # store properties as artifact for inspection\n",
    "            props_path = 'job_properties_{}.json'.format(returned_job.name)\n",
    "            with open(props_path, 'w') as pf:\n",
    "                json.dump(job_details.properties, pf)\n",
    "            mlflow.log_artifact(props_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print('MLflow run id:', run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f00feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve job details and best child run information\n",
    "job_details = ml_client.jobs.get(returned_job.name)\n",
    "print('Job status:', job_details.status)\n",
    "\n",
    "# The SDK v2 job object contains child jobs/trials in properties (inspect job_details to find best trial)\n",
    "print(job_details.__dict__.keys())\n",
    "\n",
    "# You can fetch returned_job or child runs from ml_client.jobs.list() and inspect metrics to find best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best child run and model details\n",
    "best_run = None\n",
    "best_run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
